{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from BinomDataset_Colorization import BinomDataset \n",
    "from CGAP_UNET_Colorization import UN\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "import torch.utils.data as dt\n",
    "from torch.utils.data import random_split\n",
    "import random\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"GPU not found, code will run on CPU and can be extremely slow!\")\n",
    "else:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "print(f'Device in use: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnrToString(inp):\n",
    "    if inp < 0:\n",
    "        return 'm'+str(-inp)\n",
    "    else:\n",
    "        return str(inp)\n",
    "\n",
    "minpsnr = -40\n",
    "maxpsnr = 30\n",
    "\n",
    "name = psnrToString(minpsnr)+\"to\"+psnrToString(maxpsnr)+\"-256x256-ffhq-colorization-full\"\n",
    "\n",
    "CHECKPOINT_PATH = ''\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "CHECKPOINT_PATH , name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxepochs = 20\n",
    "dataset_path = ''\n",
    "dataset = BinomDataset(root = dataset_path, windowSize = 256, minPSNR = minpsnr, maxPSNR = maxpsnr, virtSize = 1)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Set the sizes for your train and test sets\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "val_size = total_size - train_size  # Remaining 20% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dt.DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True, pin_memory=False, num_workers=4)\n",
    "val_loader = dt.DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=True,  pin_memory=False, num_workers=4)\n",
    "\n",
    "trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, name), gradient_clip_val=0.5,\n",
    "                     accelerator=\"gpu\",\n",
    "                     max_epochs=maxepochs, \n",
    "                     callbacks=[ModelCheckpoint(save_weights_only=False, mode=\"min\", monitor=\"val_loss\", every_n_epochs= 1),\n",
    "                                LearningRateMonitor(\"epoch\"),\n",
    "                                EarlyStopping('val_loss', patience=2000)])\n",
    "\n",
    "model = UN(channels = 3, levels=10, depth=7, start_filts=32, \n",
    "           up_mode = 'upsample', merge_mode = 'concat').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.save_checkpoint(os.path.join(CHECKPOINT_PATH, name)+'.ckpt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
