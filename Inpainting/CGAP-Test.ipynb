{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Full GAP - Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from skimage import io, measure\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"GPU not found, code will run on CPU and can be extremely slow!\")\n",
    "else:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as dt\n",
    "\n",
    "import time\n",
    "import os\n",
    "from CGAP_UNET_Super_Res import UN\n",
    "from BinomDataset_Super_Res import BinomDataset\n",
    "from inference import sample_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inp):\n",
    "    ''' \n",
    "    Preprocess images from dataset for plt.imshow\n",
    "    '''\n",
    "    if isinstance(inp, np.ndarray):\n",
    "        img = inp.copy()\n",
    "        img/=img.max()\n",
    "        return img.transpose(1, 2, 0)\n",
    "    elif torch.is_tensor(inp):\n",
    "        img = inp.clone()\n",
    "        img/=img.max()\n",
    "        return img.permute(1, 2, 0)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'm40to30-256x256-ffhq-inpainting-full'\n",
    "CHECKPOINT_PATH = ''\n",
    "\n",
    "model = UN(channels = 3, levels=10, depth=7,start_filts=32, \n",
    "           up_mode = 'upsample', merge_mode = 'concat').to(device)\n",
    "model = UN.load_from_checkpoint(os.path.join(CHECKPOINT_PATH, name)+'.ckpt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_input = #grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "batch_size = 1\n",
    "pixels_x = 256\n",
    "pixels_y = 256\n",
    "\n",
    "inp_img =  torch.zeros(batch_size, channels, pixels_y, pixels_x)\n",
    "\n",
    "cond_img = cond_input\n",
    "\n",
    "input_img = torch.cat((cond_img, inp_img), 1).to(device)\n",
    "\n",
    "for i in range(1):\n",
    "    startTime = time.time()\n",
    "    denoised, photons, stack, iterations = sample_image(input_img,\n",
    "                                                        model, \n",
    "                                                        beta = 0.1,\n",
    "                                                        save_every_n = 10,\n",
    "                                                        max_psnr = 30,\n",
    "                                                        max_its = 20000000,\n",
    "                                                        channels = 3)\n",
    "    for j in range(denoised.shape[0]):\n",
    "            denoised/=denoised.mean()\n",
    "            print(denoised.shape)\n",
    "            plt.figure(figsize = (5,5))\n",
    "            plt.imshow(preprocess(denoised[0]), vmin = 0,\n",
    "                       vmax = np.percentile(denoised[0],99.99))\n",
    "            plt.title('Generative')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure(figsize = (5,5))\n",
    "            plt.imshow(preprocess(photons[0]), vmin = 0,\n",
    "                       vmax = np.percentile(photons[j],99.99))\n",
    "            plt.title('Photon counts')\n",
    "            plt.show()\n",
    "\n",
    "    print('_______________________________________', iterations)\n",
    "\n",
    "    endTime = time.time()\n",
    "    elapsedTime = endTime - startTime\n",
    "    print ('time (s):', elapsedTime, 'time per image (s)', elapsedTime/denoised.shape[0])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Full GAP - Diversity Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = ''\n",
    "dataset = BinomDataset(img_path, 256, -30, -20, 1)\n",
    "img = dataset[0]\n",
    "\n",
    "input_img = torch.cat((cond_img, img), 1).to(device)\n",
    "\n",
    "for i in range(1):\n",
    "    startTime = time.time()\n",
    "    denoised, photons, stack, iterations = sample_image(input_img,\n",
    "                                                        model, \n",
    "                                                        beta = 0.1,\n",
    "                                                        save_every_n = 10,\n",
    "                                                        max_psnr = 30,\n",
    "                                                        max_its = 20000000,\n",
    "                                                        channels = 3)\n",
    "    for j in range(denoised.shape[0]):\n",
    "            denoised/=denoised.mean()\n",
    "            print(denoised.shape)\n",
    "            plt.figure(figsize = (5,5))\n",
    "            plt.imshow(preprocess(denoised[0]), vmin = 0,\n",
    "                       vmax = np.percentile(denoised[0],99.99))\n",
    "            plt.title('Generative')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure(figsize = (5,5))\n",
    "            plt.imshow(preprocess(photons[0]), vmin = 0,\n",
    "                       vmax = np.percentile(photons[j],99.99))\n",
    "            plt.title('Photon counts')\n",
    "            plt.show()\n",
    "\n",
    "    print('_______________________________________', iterations)\n",
    "\n",
    "    endTime = time.time()\n",
    "    elapsedTime = endTime - startTime\n",
    "    print ('time (s):', elapsedTime, 'time per image (s)', elapsedTime/denoised.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Cascaded GAP\n",
    "\n",
    "load model1, model2, model3, model4 and model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Inference_cascade import sample_image\n",
    "channels = 3\n",
    "batch_size = 1\n",
    "pixels_x = 256\n",
    "pixels_y = 256\n",
    "\n",
    "inp_img =  torch.zeros(batch_size, channels, pixels_y, pixels_x)\n",
    "\n",
    "cond_img = cond_input\n",
    "\n",
    "input_img = torch.cat((cond_img, inp_img), 1).to(device)\n",
    "\n",
    "for i in range(1):\n",
    "    startTime = time.time()\n",
    "    denoised, photons, stack, iterations = sample_image(input_img,\n",
    "                                                        [model1, model2, model3, model4, model5], \n",
    "                                                        beta = 0.1,\n",
    "                                                        save_every_n = 10,\n",
    "                                                        max_psnr = 30,\n",
    "                                                        max_its = 20000000,\n",
    "                                                        channels = 3)\n",
    "    for j in range(denoised.shape[0]):\n",
    "            denoised/=denoised.mean()\n",
    "            print(denoised.shape)\n",
    "            plt.figure(figsize = (5,5))\n",
    "            plt.imshow(preprocess(denoised[0]), vmin = 0,\n",
    "                       vmax = np.percentile(denoised[0],99.99))\n",
    "            plt.title('Generative')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure(figsize = (5,5))\n",
    "            plt.imshow(preprocess(photons[0]), vmin = 0,\n",
    "                       vmax = np.percentile(photons[j],99.99))\n",
    "            plt.title('Photon counts')\n",
    "            plt.show()\n",
    "\n",
    "    print('_______________________________________', iterations)\n",
    "\n",
    "    endTime = time.time()\n",
    "    elapsedTime = endTime - startTime\n",
    "    print ('time (s):', elapsedTime, 'time per image (s)', elapsedTime/denoised.shape[0])\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
